{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import traceback\n",
    "import watchdog\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import LoggingEventHandler\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from enum import Enum, auto\n",
    "\n",
    "import wolff\n",
    "import wolff_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_files: ['/Users/s3182541/STSP/Decoding/data/final/exp2/1/sigma1_1.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/1/data1.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/1/sigma1.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/1/sigma1_0.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/1/angles.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/1/data2.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/2/data1.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/2/angles.npy', '/Users/s3182541/STSP/Decoding/data/final/exp2/2/data2.npy']\n",
      "processed_files: set()\n",
      "Starting with /Users/s3182541/STSP/Decoding/data/final/exp2/1, module 1\n",
      "Loading data...\n",
      "Loading data...\n",
      "Loading angles...\n",
      "Loading sigma...\n",
      "Loading angles...\n",
      "Loading sigma...\n",
      "All files loaded\n",
      "Decoding...\n",
      "(864, 17, 2300)\n",
      "All files loaded\n",
      "Decoding...\n",
      "(864, 17, 2300)\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "Trial 1/864\n",
      "Trial 1/864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in converted code:\n",
      "\n",
      "    /Users/s3182541/STSP/Decoding/wolff_cross.py:100 parallel  *\n",
      "        return tf.map_fn(calc_dist_part,\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py:275 map_fn\n",
      "        elem.get_shape().with_rank_at_least(1)[0])))\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py:309 merge_with\n",
      "        self.assert_is_compatible_with(other)\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py:276 assert_is_compatible_with\n",
      "        (self, other))\n",
      "\n",
      "    ValueError: Dimensions 2300 and 600 are not compatible\n",
      "\n",
      "in converted code:\n",
      "\n",
      "    /Users/s3182541/STSP/Decoding/wolff_cross.py:100 parallel  *\n",
      "        return tf.map_fn(calc_dist_part,\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py:275 map_fn\n",
      "        elem.get_shape().with_rank_at_least(1)[0])))\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py:309 merge_with\n",
      "        self.assert_is_compatible_with(other)\n",
      "    /home/s3182541/.conda/envs/stsp/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py:276 assert_is_compatible_with\n",
      "        (self, other))\n",
      "\n",
      "    ValueError: Dimensions 2300 and 600 are not compatible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/s3182541/STSP/Decoding/data/final/exp2'\n",
    "device_i = 0\n",
    "\n",
    "def load_file(file, mmap=None):\n",
    "    while True:\n",
    "        try:\n",
    "            arr = np.load(file, mmap_mode=mmap)\n",
    "            break\n",
    "        except (OSError, ValueError) as e:\n",
    "            print(str(e))\n",
    "            print(\"Error reading file, trying again...\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def decode_part(dat_range, path, module, path_sigma, save_file, device_i):\n",
    "    start_t = time.time()\n",
    "    \n",
    "    if not exists(save_file):\n",
    "        print(\"Loading data...\")\n",
    "        data = load_file(join(path, \"data\" + module + \".npy\"), 'r')\n",
    "        data = data[dat_range].copy()\n",
    "        print(\"Loading angles...\")\n",
    "        angles = load_file(join(path, \"angles.npy\"), 'r')\n",
    "        angles = angles[dat_range].copy()\n",
    "        print(\"Loading sigma...\")\n",
    "        sigma = load_file(path_sigma)\n",
    "        print(\"All files loaded\")\n",
    "        \n",
    "        bin_width = np.pi / 6\n",
    "\n",
    "        print(\"Decoding...\")\n",
    "        cross_cos_amp = wolff_cross.cross_decode(data, angles, bin_width, sigma, device_i)\n",
    "#         cross_cos_amp = wolff_cross.cross_decode(data, angles, bin_width, sigma, 2)\n",
    "\n",
    "        c = np.mean(cross_cos_amp, 0)\n",
    "\n",
    "        np.save(save_file, c)\n",
    "    \n",
    "    print(\"Done with \" + save_file)\n",
    "    end_t = time.time()\n",
    "    \n",
    "    with open(join(path, \"diagnostics.txt\"), 'a') as f:\n",
    "        f.write(str(end_t - start_t) + \"\\n\")\n",
    "\n",
    "def calc_sigmas(len_i, split_i, path, module):\n",
    "    data = load_file(join(path, \"data\" + module + \".npy\"), 'r')\n",
    "    data0 = data[range(split_i)].copy()\n",
    "    data1 = data[range(split_i, len_i)].copy()\n",
    "    \n",
    "    path0 = join(path, \"sigma\" + module + \"_0.npy\")\n",
    "    path1 = join(path, \"sigma\" + module + \"_1.npy\")\n",
    "    \n",
    "    if not exists(path0):\n",
    "        sigma0 = wolff_cross.prepare_sigma(data0)\n",
    "        np.save(path0, sigma0)\n",
    "    \n",
    "    if not exists(path1):\n",
    "        sigma1 = wolff_cross.prepare_sigma(data1)\n",
    "        np.save(path1, sigma1)\n",
    "    \n",
    "    return (path0, path1)\n",
    "    \n",
    "def err_handler(e):\n",
    "    print(str(e))\n",
    "    traceback.print_tb(e.__traceback__)\n",
    "    \n",
    "def decode_file(pool, path, module):\n",
    "    save_file = \"c\" + module\n",
    "    save_file = join(path, save_file)\n",
    "    \n",
    "    print(\"Starting with \" + path + \", module \" + module)\n",
    "\n",
    "    # Split up all data evenly\n",
    "    angles = load_file(join(path, \"angles.npy\"), 'r') # We have to load this to check its length\n",
    "    len_i = len(angles)\n",
    "    split_i = int(len_i / 2)\n",
    "    \n",
    "    path_sigma0, path_sigma1 = calc_sigmas(len_i, split_i, path, module)\n",
    "    \n",
    "    global device_i\n",
    "\n",
    "    pool.apply_async(decode_part, \n",
    "                     (range(split_i), path, module, path_sigma0, save_file+\"_0.npy\", device_i), \n",
    "                     error_callback=err_handler)\n",
    "    device_i = (device_i + 1) % 3\n",
    "    \n",
    "    pool.apply_async(decode_part, \n",
    "                     (range(split_i, len_i), path, module, path_sigma1, save_file+\"_1.npy\", device_i), \n",
    "                     error_callback=err_handler)\n",
    "    device_i = (device_i + 1) % 3\n",
    "    \n",
    "def get_present_files():\n",
    "    files = []\n",
    "    pat = re.compile(r\"(data)|(sigma)|(angles)\")\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        files += ([join(dirpath, f) for f in filenames if pat.search(f)])\n",
    "        \n",
    "    return files\n",
    "\n",
    "class PrepDataHandler(watchdog.events.FileSystemEventHandler):\n",
    "    def __init__(self):\n",
    "        super(PrepDataHandler, self).__init__()\n",
    "        self.files = []\n",
    "    \n",
    "    def on_created(self, event):\n",
    "        if not event.is_directory:\n",
    "            self.files.append(event.src_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processed_files = set()\n",
    "    new_files = get_present_files()\n",
    "    \n",
    "    event_handler = PrepDataHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path, recursive=True)\n",
    "    observer.start()\n",
    "    try:\n",
    "        with mp.Pool(3) as pool:\n",
    "            while True:\n",
    "                # if there is a new file, get its name, check whether it's a data file\n",
    "                # and check whether the angles file is present; then you can begin decoding\n",
    "                time.sleep(1)\n",
    "\n",
    "                new_files = new_files + [path for path in event_handler.files if path not in processed_files]\n",
    "                \n",
    "                if new_files:\n",
    "                    print(\"new_files:\", new_files)\n",
    "                    print(\"processed_files:\", processed_files)\n",
    "                    \n",
    "                    for file in new_files:\n",
    "                        f_dir, f_name = os.path.split(file)\n",
    "                        \n",
    "                        if re.search(r\"angles.npy\", f_name):\n",
    "                            if join(f_dir, \"data1.npy\") in processed_files \\\n",
    "                              and join(f_dir, \"sigma1.npy\") in processed_files:\n",
    "                                decode_file(pool, f_dir, \"1\")\n",
    "                                \n",
    "                            if join(f_dir, \"data2.npy\") in processed_files \\\n",
    "                              and join(f_dir, \"sigma2.npy\") in processed_files:\n",
    "                                decode_file(pool, f_dir, \"2\")\n",
    "                        \n",
    "                        if re.search(r\"data\", f_name) or re.search(r\"sigma\", f_name):\n",
    "                            module = re.sub(r\"(data)|(sigma)|(\\.npy)\", \"\", f_name)\n",
    "                            dat_file = \"data\" + module + \".npy\"\n",
    "                            sig_file = \"sigma\" + module + \".npy\"\n",
    "                            \n",
    "                            deps = join(f_dir, \"angles.npy\") in processed_files\n",
    "                            dat_dep = f_name == dat_file or join(f_dir, dat_file) in processed_files\n",
    "                            sig_dep = f_name == sig_file or join(f_dir, sig_file) in processed_files\n",
    "                            deps = deps and dat_dep and sig_dep\n",
    "                            \n",
    "                            if deps:\n",
    "                                decode_file(pool, f_dir, module)\n",
    "                            \n",
    "                        processed_files.add(file)\n",
    "                \n",
    "                new_files = []\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('/Users/s3182541/temp', \"diagnostics.txt\"), 'a') as f:\n",
    "    f.write(\"hi\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/s3182541/STSP/Decoding/data/final/exp1/2/angles.npy',\n",
       " '/Users/s3182541/STSP/Decoding/data/final/exp1/2/sigma2.npy',\n",
       " '/Users/s3182541/STSP/Decoding/data/final/exp1/2/data1.npy',\n",
       " '/Users/s3182541/STSP/Decoding/data/final/exp1/1/sigma2.npy',\n",
       " '/Users/s3182541/STSP/Decoding/data/final/exp1/1/angles.npy',\n",
       " '/Users/s3182541/STSP/Decoding/data/final/exp1/1/data1.npy']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_present_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1], [2], [3], [4]])\n",
    "arr[range(2, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/share/Chiel4Loran/Decoding/exp2/subj_1_initial_angles_2.npy',\n",
       " '/Users/share/Chiel4Loran/Decoding/exp2/subj_1_initial_angles_3.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = ['/Users/share/Chiel4Loran/Decoding/exp2/subj_1_initial_angles_3.npy', \n",
    "          '/Users/share/Chiel4Loran/Decoding/exp2/subj_1_initial_angles_2.npy']\n",
    "sorted(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-7-acedb7a363e3>\", line 2, in <module>\n",
      "    raise ValueError(\"Some error\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raise ValueError(\"Some error\")\n",
    "except ValueError as e:\n",
    "    traceback.print_tb(e.__traceback__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 17, 2300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/Users/s3182541/STSP/Decoding/data/final/exp2/1/data1.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
